{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Import all libs.\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import numpy as np\n",
    "import json\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications import InceptionV3\n",
    "from keras.layers import Dense, Flatten, Activation, Dropout, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, applications\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras import backend as K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ Annotation File\n",
    "annot_file = '../input/inaturalist-2019-fgvc6/train2019.json'\n",
    "with open(annot_file) as f:\n",
    "        train_annot = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_raw = pd.DataFrame(train_annot['annotations'])[['image_id','category_id']]\n",
    "df_train_img = pd.DataFrame(train_annot['images'])[['id', 'file_name']].rename(columns={'id':'image_id'})\n",
    "df_train_cons = pd.merge(df_train_img, df_train_raw, on='image_id')\n",
    "df_train_cons['category_id']=df_train_cons ['category_id'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of train images ' + str(len(df_train_cons['image_id'])))\n",
    "print('Number of classes      ' + str(len(df_train_cons['category_id'].unique())))\n",
    "\n",
    "x, y = np.unique(df_train_cons['category_id'], return_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding statistical values on no. of images\n",
    "# and 1st max. and \n",
    "import statistics\n",
    "\n",
    "y.mean(),y.std(),y.std()/y.mean(),y.max(),y.min(),y.sum(),np.argmax(y),np.argmin(y),statistics.mode(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "List = pd.DataFrame({\"id\":x,\"count\":y})\n",
    "List.to_csv(\"ImageCount.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(16,10), facecolor='white', dpi= 150)\n",
    "\n",
    "plt.title(' Number of Training Images vs Classes')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of Training Images per Class')\n",
    "ax.stem( y, linefmt= ' ',basefmt=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_annot = '../input/inaturalist-2019-fgvc6/val2019.json'\n",
    "with open(valid_annot) as f:\n",
    "        valid_annot = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_raw = pd.DataFrame(valid_annot['annotations'])[['image_id','category_id']]\n",
    "df_valid_img = pd.DataFrame(valid_annot['images'])[['id', 'file_name']].rename(columns={'id':'image_id'})\n",
    "df_valid_cons = pd.merge(df_valid_img, df_valid_raw, on='image_id')\n",
    "df_valid_cons['category_id']=df_valid_cons['category_id'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Valid images ' + str(len(df_valid_cons['image_id'])))\n",
    "print('Number of classes      ' + str(len(df_valid_cons['category_id'].unique())))\n",
    "\n",
    "xi, yi = np.unique(df_valid_cons['category_id'], return_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,10), facecolor='white', dpi= 150)\n",
    "\n",
    "plt.title(' Number of Validation Images vs Classes')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of Validation Images per Class')\n",
    "ax.stem( yi, linefmt= ' ',basefmt=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 299\n",
    "nCLASSES = 1010\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1./255, \n",
    "    horizontal_flip = True,    \n",
    "    zoom_range = 0.3,\n",
    "    width_shift_range = 0.3,\n",
    "    height_shift_range=0.3\n",
    "    )\n",
    "train_generator=train_datagen.flow_from_dataframe(\n",
    "    dataframe=df_train_cons,\n",
    "    directory= \"../input/inaturalist-2019-fgvc6/train_val2019\",\n",
    "    x_col=\"file_name\",\n",
    "    y_col=\"category_id\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",    # mode=\"raw\" for regression\n",
    "    target_size=(IMG_SIZE,IMG_SIZE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "valid_generator=valid_datagen.flow_from_dataframe(\n",
    "    dataframe=df_valid_cons,\n",
    "    directory=\"../input/inaturalist-2019-fgvc6/train_val2019\",\n",
    "    x_col=\"file_name\",\n",
    "    y_col=\"category_id\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",    \n",
    "    target_size=(IMG_SIZE,IMG_SIZE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = int(np.ceil(len(train_generator)/BATCH_SIZE))\n",
    "valid_steps = int(np.ceil(len(valid_generator)/BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model = applications.InceptionV3(weights=None, \n",
    "                              include_top=True, \n",
    "                              input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "original_model.load_weights('../input/inceptionv3/inception_v3_weights_ai.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_input  = original_model.get_layer(index=0).input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get second to last model layer.\n",
    "bottleneck_output = original_model.get_layer(index=-2).output\n",
    "bottleneck_model  = Model(inputs=bottleneck_input,outputs=bottleneck_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Sequential()\n",
    "new_model.add(bottleneck_model)\n",
    "# new_model.add(Dense(1024, activation='ReLU', input_dim=2048))\n",
    "# model.add(Dropout(rate=0.2))\n",
    "# new_model.add(Dense(1024, activation='ReLU'))\n",
    "# model.add(Dropout(rate=0.2))\n",
    "new_model.add(Dense(nCLASSES, activation='softmax', input_dim=2048))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"mINCEPTION.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "ES = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "# Adam episilon (default), decay (default)\n",
    "new_model.compile(optimizers.Adam(lr=0.0001,beta_1=0.9,beta_2=0.999),loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "perf = new_model.fit_generator(generator=train_generator,                   \n",
    "                                    steps_per_epoch = train_steps,\n",
    "                                    validation_data = valid_generator,                    \n",
    "                                    validation_steps = valid_steps,\n",
    "                                    epochs = N_EPOCHS,\n",
    "                                    callbacks = [checkpoint, ES],\n",
    "                                    verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot perf. graph\n",
    "\n",
    "\n",
    "with open('perf.json', 'w') as f:\n",
    "    json.dump(perf.history, f)\n",
    "\n",
    "df_metric = pd.DataFrame(perf.history)\n",
    "df_metric[['loss', 'val_loss']].plot()\n",
    "df_metric[['acc', 'val_acc']].plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_annot = '../input/inaturalist-2019-fgvc6/test2019.json'\n",
    "with open(test_annot) as f:\n",
    "        test_annot = json.load(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_img = pd.DataFrame(test_annot['images'])[['id', 'file_name']].rename(columns={'id':'image_id'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction generator\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(      \n",
    "        dataframe = df_test_img,    \n",
    "        directory = \"../input/inaturalist-2019-fgvc6/test2019\",    \n",
    "        x_col=\"file_name\",\n",
    "        target_size = (IMG_SIZE,IMG_SIZE),\n",
    "        batch_size = 1,\n",
    "        shuffle = False,\n",
    "        class_mode = None\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2index = (train_generator.class_indices)\n",
    "idx2label = dict((i,j) for j,i in label2index.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "prediction = new_model.predict_generator(test_generator, steps = len(test_generator.filenames))\n",
    "# prediction = new_model.predict_generator(test_generator, steps = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(prediction,axis=1)\n",
    "prediction = [idx2label[j] for j in predicted_classes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = test_generator.filenames\n",
    "results = pd.DataFrame({\"file_name\":filenames,\"predicted\":prediction})\n",
    "df_result = pd.merge(df_test_img, results, on='file_name')[['image_id','predicted']].rename(columns={'image_id':'id'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv(\"submission.csv\",index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
